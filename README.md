# Long-Short-Term-Memory for Sentence Generation

In this project, a sentence generator is developed using LSTM modules. To optimize the final model, there are several aspects that can be optimized. Among those aspects, Hidden Dimension, Number of Layers, Embedding Dim, and Learning Rate was studied.

# Case Study
In case studies other parameters of the model was fixed to ensure accurate comparision.
<table>
  <tr>
    <td>
      <table>
        <tr>
          <td> Model name </td>
          <td> H10 </td>
          <td> H100 </td>
          <td> S1</td>
          <td> S5 </td>
          <td> E50 </td>
          <td> E200 </td>
          <td> LR0.1 </td>
          <td> LR0.01 </td>
        </tr>
        <tr>
          <td> Embedding Size </td>
          <td> 50 </td>
          <td> 50 </td>
          <td> 50</td>
          <td> 50 </td>
          <td> 50 </td>
          <td> <p color="red">200</p> </td>
          <td> 50 </td>
          <td> 50 </td>
        </tr>
        <tr>
          <td> Hidden Layer Size </td>
          <td> 10 </td>
          <td> 100 </td>
          <td> 10</td>
          <td> 10 </td>
          <td> 10 </td>
          <td> 10 </td>
          <td> 10 </td>
          <td> 10 </td>
        </tr>
        <tr>
          <td> Number of Layers </td>
          <td> 2 </td>
          <td> 2 </td>
          <td> 1</td>
          <td> 5 </td>
          <td> 2 </td>
          <td> 2 </td>
          <td> 2 </td>
          <td> 2 </td>
        </tr>
        <tr>
          <td> Batch Size </td>
          <td> 256 </td>
          <td> 256 </td>
          <td> 256</td>
          <td> 256 </td>
          <td> 256 </td>
          <td> 256 </td>
          <td> 256 </td>
          <td> 256 </td>
        </tr>
         <tr>
          <td> Epochs </td>
          <td> 50 </td>
          <td> 50 </td>
          <td> 50</td>
          <td> 50 </td>
          <td> 50 </td>
          <td> 50 </td>
          <td> 50 </td>
          <td> 50 </td>
        </tr>
        <tr>
          <td> Learning Rate </td>
          <td> 0.10 </td>
          <td> 0.10 </td>
          <td> 0.10 </td>
          <td> 0.10 </td>
          <td> 0.10 </td>
          <td> 0.10 </td>
          <td> 0.10 </td>
          <td> 0.01 </td>
        </tr>
      </table>
  </tr>
 </table>
## Hidden Dimension

## Number of Layers

## Embedding Dimension

## Learning Rate
